# PathGuardian ğŸ›¡ï¸

**Adaptive Navigation & Location Intelligence for Individuals with Special Needs**

---

## Problem Statement

> **Women in Tech â€” Problem Statement 1 (#19)**

Individuals with special needs often face persistent barriers to communication, education, mobility, and daily independence due to limited access to inclusive technologies and support systems. These challenges are further intensified for people who rely on sign language, especially those using diverse sign language dialects, where existing solutions frequently fail to account for regional variations, non-standardized gestures, and contextual nuances. As a result, many individuals remain socially isolated, face difficulties accessing essential services, and experience reduced opportunities for learning, employment, and community participation.

Current assistive technologies often focus on single-modality solutions (e.g., speech-to-text, basic sign recognition, or simple navigation aids), which do not fully address the complex and multi-layered needs of users with disabilities. The fragmentation of these tools and the lack of multimodal integration limit their real-world effectiveness and scalability.

**PathGuardian** addresses this challenge by providing an **adaptive, multimodal navigation and location intelligence system** that combines vision (map-based guidance), audio (ambient environment detection), text (simplified UI), and AI-driven context awareness into a cohesive system. It adapts to individual needs â€” empowering seniors and individuals with disabilities to navigate independently while keeping caregivers informed and reassured.

---

## What PathGuardian Solves

| Challenge | How PathGuardian Addresses It |
|-----------|-------------------------------|
| **Mobility barriers** | Safety-first routing with landmark-based navigation, large UI, voice input |
| **Social isolation** | Enables independent outings with caregiver confidence |
| **Fragmented tools** | Single app combines navigation, tracking, alerts, check-ins, and ambient sensing |
| **Caregiver anxiety** | Real-time dashboard with proactive alerts and one-tap check-in |
| **Privacy concerns** | "Private Time" toggle lets users pause tracking when desired |
| **Battery drain** | Adaptive GPS polling â€” slower updates when stationary |
| **Environmental awareness** | Microphone-based ambient sound analysis detects surroundings (park, mall, street) |

---

## Key Features

### ğŸ§­ Adaptive Navigation (Senior / Care Recipient)
- **Safety-First Routing** â€” Prioritizes sidewalks and well-lit areas over speed
- **Simplified Interface** â€” High-contrast, large buttons (>44px touch targets), senior-friendly
- **Voice Input** â€” Simulated voice command for destination entry
- **Text Destination Input** â€” Type any known location (museum, pharmacy, park, etc.) and press Enter
- **Red Destination Marker** â€” Visual red dot on the map showing the end destination
- **Turn-by-Turn Navigation** â€” Real-time directional guidance overlay
- **Privacy Controls** â€” "Private Time" toggle pauses location sharing
- **ğŸ™ï¸ Ambient Environment Detection** â€” Uses real microphone to analyze surroundings and classify environment (Quiet Park ğŸŒ³, Busy Street ğŸš—, Shopping Area ğŸ›ï¸, etc.)

### ğŸ“Š Caregiver Dashboard
- **Live Map Tracking** â€” Real-time location with smooth GPS simulation
- **Proactive Alerts** â€” Deviation detection, arrival/departure notifications
- **ğŸ”” Multi-Person Alert Log** â€” Consolidated alerts from multiple care recipients (Margaret, Robert, Helen, James) with severity filtering (High/Medium/Low/Info)
- **ğŸ‘‹ Big Check-In Notification** â€” Full-screen animated overlay showing "Check-In Sent!" and the reply in large fonts
- **ğŸ•’ Journey History** â€” Timeline of past journeys and alerts with day grouping and filtering
- **One-Tap Check-In** â€” Send a gentle "Are you okay?" prompt

---

## Technology Stack

| Layer | Technology |
|-------|-----------|
| **Structure** | HTML5 (Semantic) |
| **Styling** | CSS3 (Custom Properties, Flexbox, Grid, Animations) |
| **Logic** | JavaScript ES6+ (Classes, Async/Await, Web APIs) |
| **Mapping** | Leaflet.js + OpenStreetMap (no API key required) |
| **Audio Analysis** | Web Audio API (FFT frequency analysis, real microphone) |
| **Fonts** | Google Fonts (Outfit) |
| **Simulation** | Custom GPS movement engine with adaptive polling |

---

## Project Structure

```
PathGuardian/
â”œâ”€â”€ index.html           # Landing page â€” role selection
â”œâ”€â”€ navigation.html      # Senior navigation interface
â”œâ”€â”€ dashboard.html       # Caregiver monitoring dashboard
â”œâ”€â”€ css/
â”‚   â””â”€â”€ style.css        # Global design system
â”œâ”€â”€ js/
â”‚   â”œâ”€â”€ app.js           # Core application logic + location database
â”‚   â”œâ”€â”€ map.js           # Leaflet.js map controller (blue user + red destination markers)
â”‚   â”œâ”€â”€ simulation.js    # GPS movement simulation engine
â”‚   â””â”€â”€ ambient.js       # Ambient sound environment analyzer (Web Audio API)
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ PRD.md               # Product Requirements Document
â”œâ”€â”€ TASK.md              # Development task tracker
â””â”€â”€ WORKFLOW.md          # Technical workflow & architecture
```

---

## Getting Started

1. **Clone the repo:**
   ```bash
   git clone https://github.com/Manutd1234/PathGuardian-.git
   cd PathGuardian-
   ```

2. **Open in browser:**
   - Open `index.html` in any modern browser (Chrome, Edge, Firefox)
   - No build step, no dependencies to install, no API keys needed

3. **Choose your role:**
   - ğŸ§“ **Care Recipient** â†’ Navigation interface with voice input, ambient detection
   - ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦ **Caregiver** â†’ Dashboard with live tracking, alerts, history

4. **Test the destination input:**
   - Type `museum`, `pharmacy`, `cafe`, `hospital`, `park`, or `home` â†’ Press Enter
   - A red destination dot appears on the map and navigation begins

5. **Test ambient sound detection:**
   - Click "Start Listening" on the navigation page
   - Allow microphone access â€” the panel shows your real environment classification

---

## Demo Walkthrough

| Step | Action | Expected Result |
|------|--------|----------------|
| 1 | Open `index.html`, click "Care Recipient" | Opens navigation page |
| 2 | Type `cafe` in "Where to?" and press Enter | Red dot appears, route draws, simulation starts |
| 3 | Click "Start Listening" on environment panel | Microphone activates, shows environment (ğŸŒ³/ğŸš—/ğŸ›ï¸) |
| 4 | Go back, click "Caregiver" | Opens dashboard with live map |
| 5 | Click "ğŸ‘‹ Check-In" | Big overlay: "Check-In Sent!" â†’ 3s â†’ "Reply Received!" |
| 6 | Click "âš™ï¸ Alerts" | Alert log with 4 people, severity-coded, filterable |
| 7 | Click "ğŸ•’ History" | Journey history timeline grouped by day |

---

## Team

Built for the **Women in Tech Hackathon** â€” Problem Statement 1 (#19)

---

## License

MIT License â€” Free to use, modify, and distribute.
